{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMQL - Language Model Query Language\n",
    "\n",
    "## Rocky Mountain AI Interest Group - Engineering Subgroup\n",
    "\n",
    "### Cameron Pope\n",
    "\n",
    "#### (Fractional) CTO - Meaningly\n",
    "\n",
    "[cameron@theaboutbox.com](mailto:cameron@theaboutbox.com)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*March 18, 2024*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "## 1. What is LMQL?\n",
    "\n",
    "## 2. What problems does it solve? \n",
    "\n",
    "## 3. Features and Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is LMQL\n",
    "\n",
    "## [LMQL](https://lmql.ai) is a programming language for LLMs\n",
    "\n",
    "- Can constrain output to generate data in an exact format (json or Python dataclasses)\n",
    "\n",
    "- Can integrate Python code for procedural prompt generation\n",
    "\n",
    "- Supports multiple model backends\n",
    "\n",
    "  - OpenAI\n",
    "\n",
    "  - Llama.cpp\n",
    "\n",
    "  - Huggingface transformers\n",
    "\n",
    "  - *Ollama is not supported...yet* [Github Issue](https://github.com/ollama/ollama/issues/2415)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "Without further ado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Tell me a knock knock joke about **Alpacas**:\n",
       "\n",
       "\n",
       "Knock Knock!\n",
       "\n",
       "*Who's there?*\n",
       "\n",
       "Alpaca\n",
       "\n",
       "*Alpaca who?*\n",
       "\n",
       "Alpaca my bags for our trip to Peru!!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lmql\n",
    "from IPython.display import Markdown\n",
    "\n",
    "@lmql.query\n",
    "async def knock_knock(subject=\"llamas\"):\n",
    "    '''lmql\n",
    "    sample(n=1, temperature=0.5)\n",
    "    \"\"\"Tell me a knock knock joke about **{subject}**:\\n\\n\n",
    "    Knock Knock!\\n\n",
    "    *Who's there?*\\n\n",
    "    \"\"\"\n",
    "    \"[WHO]\\n\\n\" where STOPS_BEFORE(WHO,\"\\n\") and STOPS_BEFORE(WHO,\".\")\n",
    "    \"*{WHO} who?*\\n\\n\"\n",
    "    \"{WHO}[REST]!\\n\" where STOPS_BEFORE(REST,\"\\n\")\n",
    "    '''\n",
    "\n",
    "resp = await knock_knock(\"Alpacas\")\n",
    "Markdown(resp.prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to use LMQL\n",
    "\n",
    "## LLM is part of a workflow\n",
    "\n",
    "- Need to take output of LLM and use it as input somewhere else\n",
    "\n",
    "- Require specific structure or schema for output\n",
    "\n",
    "## Using LLM for classification tasks\n",
    "\n",
    "- Sentiment analysis\n",
    "\n",
    "- Question-answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar projects\n",
    "\n",
    "- [Guidance](https://github.com/guidance-ai/guidance)\n",
    "- [Outlines](https://github.com/outlines-dev/outlines)\n",
    "- [GBNF](https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md)\n",
    "- [TypeChat](https://github.com/microsoft/TypeChat)\n",
    "- [JsonFormer](https://github.com/1rgs/jsonformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having Technology Problems?\n",
    "\n",
    "I am available for fractional CTO / technology projects. If your organization is feeling stuck, having technology issues, or is wondering how to better leverage AI and other technologies, please reach out:\n",
    "\n",
    "[cameron@theaboutbox.com](mailto:cameron@theaboutbox.com)\n",
    "\n",
    "[LinkedIn](https://www.linkedin.com/in/theaboutbox/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmql-demo-g2XuB1Kg-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
